{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8章: 機械学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>目次</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [70. データの入手・整形](#prob70)\n",
    "- [71. ストップワード](#prob71)\n",
    "- [72. 素性抽出](#prob72)\n",
    "- [73. 学習](#prob73)\n",
    "- [74. 予測](#prob74)\n",
    "- [75. 素性の重み](#prob75)\n",
    "- [76. ラベル付け](#prob76)\n",
    "- [77. 正解率の計測](#prob77)\n",
    "- [78. 5分割交差検定](#prob78)\n",
    "- [79. 適合率-再現率グラフの描画](#prob79)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='prob70'>\n",
    "# 70.データの入手・整形"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文に関する極性分析の正解データを用い，以下の要領で正解データ（sentiment.txt）を作成せよ．<br>\n",
    "\n",
    "rt-polarity.posの各行の先頭に\"+1 \"という文字列を追加する（極性ラベル\"+1\"とスペースに続けて肯定的な文の内容が続く）<br>\n",
    "rt-polarity.negの各行の先頭に\"-1 \"という文字列を追加する（極性ラベル\"-1\"とスペースに続けて否定的な文の内容が続く）<br>\n",
    "上述1と2の内容を結合（concatenate）し，行をランダムに並び替える<br>\n",
    "sentiment.txtを作成したら，正例（肯定的な文）の数と負例（否定的な文）の数を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-08-17 13:38:40--  http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz\n",
      "www.cs.cornell.edu (www.cs.cornell.edu) をDNSに問いあわせています... 132.236.207.20\n",
      "www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.20|:80 に接続しています... 接続しました。\n",
      "HTTP による接続要求を送信しました、応答を待っています... 200 OK\n",
      "長さ: 487770 (476K) [application/x-gzip]\n",
      "`./data/rt-polaritydata.tar.gz' に保存中\n",
      "\n",
      "rt-polaritydata.tar 100%[===================>] 476.34K   273KB/s 時間 1.7s     \n",
      "\n",
      "2018-08-17 13:38:43 (273 KB/s) - `./data/rt-polaritydata.tar.gz' へ保存完了 [487770/487770]\n",
      "\n",
      "rt-polaritydata.README.1.0.txt\n",
      "rt-polaritydata/rt-polarity.neg\n",
      "rt-polaritydata/rt-polarity.pos\n"
     ]
    }
   ],
   "source": [
    "!wget -NP ./data/ http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz;\\\n",
    "tar zxvf ./data/rt-polaritydata.tar.gz -C ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \n",
      "the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth . \n",
      "effective but too-tepid biopic\n",
      "if you sometimes like to go to the movies to have fun , wasabi is a good place to start . \n",
      "emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one . \n",
      "the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game . \n",
      "offers that rare combination of entertainment and education . \n",
      "perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions . \n",
      "steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off . \n",
      "take care of my cat offers a refreshingly different slice of asian cinema . \n"
     ]
    }
   ],
   "source": [
    "!cat ./data/rt-polaritydata/rt-polarity.pos 2>/dev/null | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simplistic , silly and tedious . \n",
      "it's so laddish and juvenile , only teenage boys could possibly find it funny . \n",
      "exploitative and largely devoid of the depth or sophistication that would make watching such a graphic treatment of the crimes bearable . \n",
      "[garbus] discards the potential for pathological study , exhuming instead , the skewed melodrama of the circumstantial situation . \n",
      "a visually flashy but narratively opaque and emotionally vapid exercise in style and mystification . \n",
      "the story is also as unoriginal as they come , already having been recycled more times than i'd care to count . \n",
      "about the only thing to give the movie points for is bravado -- to take an entirely stale concept and push it through the audience's meat grinder one more time . \n",
      "not so much farcical as sour . \n",
      "unfortunately the story and the actors are served with a hack script . \n",
      "all the more disquieting for its relatively gore-free allusions to the serial murders , but it falls down in its attempts to humanize its subject . \n"
     ]
    }
   ],
   "source": [
    "!cat ./data/rt-polaritydata/rt-polarity.neg 2>/dev/null | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/rt-polaritydata/rt-polarity.pos', encoding='ISO-8859-1') as f, open('./work/rt-polarity_labeled.pos', 'w') as out:\n",
    "    for line in f:\n",
    "        print('+1', line.rstrip(), file=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/rt-polaritydata/rt-polarity.neg', encoding='ISO-8859-1') as f, open('./work/rt-polarity_labeled.neg', 'w') as out:\n",
    "    for line in f:\n",
    "        print('-1', line.rstrip(), file=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positive examples: 5331, number of negative examples: 5331\n"
     ]
    }
   ],
   "source": [
    "import itertools, more_itertools\n",
    "\n",
    "count_pos = 0\n",
    "count_neg = 0\n",
    "with open('./work/sentiment.txt', 'w') as out,\\\n",
    "open('./work/rt-polarity_labeled.pos') as pos, open('./work/rt-polarity_labeled.neg') as neg:\n",
    "    sen_concat = itertools.chain((line for line in pos), (line for line in neg))\n",
    "    for line in more_itertools.random_permutation(sen_concat):\n",
    "        if line.startswith('+1'):\n",
    "            count_pos += 1\n",
    "        else: count_neg += 1\n",
    "        print(line.rstrip(), file=out)\n",
    "    \n",
    "print('number of positive examples: {}, number of negative examples: {}'.format(count_pos, count_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+1 the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "+1 the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "+1 effective but too-tepid biopic\n",
      "+1 if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\n",
      "+1 emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\n",
      "+1 the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .\n",
      "+1 offers that rare combination of entertainment and education .\n",
      "+1 perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\n",
      "+1 steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\n",
      "+1 take care of my cat offers a refreshingly different slice of asian cinema .\n"
     ]
    }
   ],
   "source": [
    "!head ./work/rt-polarity_labeled.pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='prob71'>\n",
    "# 71. ストップワード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "英語のストップワードのリスト（ストップリスト）を適当に作成せよ．<br>\n",
    "さらに，引数に与えられた単語（文字列）がストップリストに含まれている場合は真，それ以外は偽を返す関数を実装せよ．<br>\n",
    "さらに，その関数に対するテストを記述せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pytestコマンド\n",
    "\n",
    "testで始まるモジュールのtestで始まる関数を実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>ストップワードとは?</h4>\n",
    "情報検索において検索語として利用する可能性がないためあらかじめ検索語から除いておくような語 -> \n",
    "- 前置詞, 接続詞, 代名詞, 冠詞(文法関係の機能語)\n",
    "- 一般的すぎる語"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href = 'https://www.ranks.nl/stopwords'>プログラムに用いたストップワードのリスト</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, NavigableString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/r-fujii/.pyenv/versions/anaconda3-5.0.1/lib/python3.7/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "res = requests.get('https://www.ranks.nl/stopwords', verify=False)\n",
    "soup = BeautifulSoup(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find_all('table')\n",
    "cols = table[0].find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "<br/>\n",
      "about\n",
      "<br/>\n",
      "above\n",
      "<br/>\n",
      "after\n",
      "<br/>\n",
      "again\n",
      "<br/>\n",
      "against\n",
      "<br/>\n",
      "all\n",
      "<br/>\n",
      "am\n",
      "<br/>\n",
      "an\n",
      "<br/>\n",
      "and\n",
      "<br/>\n",
      "any\n",
      "<br/>\n",
      "are\n",
      "<br/>\n",
      "aren't\n",
      "<br/>\n",
      "as\n",
      "<br/>\n",
      "at\n",
      "<br/>\n",
      "be\n",
      "<br/>\n",
      "because\n",
      "<br/>\n",
      "been\n",
      "<br/>\n",
      "before\n",
      "<br/>\n",
      "being\n",
      "<br/>\n",
      "below\n",
      "<br/>\n",
      "between\n",
      "<br/>\n",
      "both\n",
      "<br/>\n",
      "but\n",
      "<br/>\n",
      "by\n",
      "<br/>\n",
      "can't\n",
      "<br/>\n",
      "cannot\n",
      "<br/>\n",
      "could\n",
      "<br/>\n",
      "couldn't\n",
      "<br/>\n",
      "did\n",
      "<br/>\n",
      "didn't\n",
      "<br/>\n",
      "do\n",
      "<br/>\n",
      "does\n",
      "<br/>\n",
      "doesn't\n",
      "<br/>\n",
      "doing\n",
      "<br/>\n",
      "don't\n",
      "<br/>\n",
      "down\n",
      "<br/>\n",
      "during\n",
      "<br/>\n",
      "each\n",
      "<br/>\n",
      "few\n",
      "<br/>\n",
      "for\n",
      "<br/>\n",
      "from\n",
      "<br/>\n",
      "further\n",
      "<br/>\n",
      "had\n",
      "<br/>\n",
      "hadn't\n",
      "<br/>\n",
      "has\n",
      "<br/>\n",
      "hasn't\n",
      "<br/>\n",
      "have\n",
      "<br/>\n",
      "haven't\n",
      "<br/>\n",
      "having\n",
      "<br/>\n",
      "he\n",
      "<br/>\n",
      "he'd\n",
      "<br/>\n",
      "he'll\n",
      "<br/>\n",
      "he's\n",
      "<br/>\n",
      "her\n",
      "<br/>\n",
      "here\n",
      "<br/>\n",
      "here's\n",
      "<br/>\n",
      "hers\n",
      "<br/>\n",
      "herself\n",
      "<br/>\n",
      "him\n",
      "<br/>\n",
      "himself\n",
      "<br/>\n",
      "his\n",
      "<br/>\n",
      "how\n",
      "<br/>\n",
      "how's\n",
      "<br/>\n",
      "i\n",
      "<br/>\n",
      "i'd\n",
      "<br/>\n",
      "i'll\n",
      "<br/>\n",
      "i'm\n",
      "<br/>\n",
      "i've\n",
      "<br/>\n",
      "if\n",
      "<br/>\n",
      "in\n",
      "<br/>\n",
      "into\n",
      "<br/>\n",
      "is\n",
      "<br/>\n",
      "isn't\n",
      "<br/>\n",
      "it\n",
      "<br/>\n",
      "it's\n",
      "<br/>\n",
      "its\n",
      "<br/>\n",
      "itself\n",
      "<br/>\n",
      "let's\n",
      "<br/>\n",
      "me\n",
      "<br/>\n",
      "more\n",
      "<br/>\n",
      "most\n",
      "<br/>\n",
      "mustn't\n",
      "<br/>\n",
      "my\n",
      "<br/>\n",
      "myself\n",
      "<br/>\n",
      "no\n",
      "<br/>\n",
      "nor\n",
      "<br/>\n",
      "not\n",
      "<br/>\n",
      "of\n",
      "<br/>\n",
      "off\n",
      "<br/>\n",
      "on\n",
      "<br/>\n",
      "once\n",
      "<br/>\n",
      "only\n",
      "<br/>\n",
      "or\n",
      "<br/>\n",
      "other\n",
      "<br/>\n",
      "ought\n",
      "<br/>\n",
      "our\n",
      "<br/>\n",
      "ours\n",
      "ourselves\n",
      "<br/>\n",
      "out\n",
      "<br/>\n",
      "over\n",
      "<br/>\n",
      "own\n",
      "<br/>\n",
      "same\n",
      "<br/>\n",
      "shan't\n",
      "<br/>\n",
      "she\n",
      "<br/>\n",
      "she'd\n",
      "<br/>\n",
      "she'll\n",
      "<br/>\n",
      "she's\n",
      "<br/>\n",
      "should\n",
      "<br/>\n",
      "shouldn't\n",
      "<br/>\n",
      "so\n",
      "<br/>\n",
      "some\n",
      "<br/>\n",
      "such\n",
      "<br/>\n",
      "than\n",
      "<br/>\n",
      "that\n",
      "<br/>\n",
      "that's\n",
      "<br/>\n",
      "the\n",
      "<br/>\n",
      "their\n",
      "<br/>\n",
      "theirs\n",
      "<br/>\n",
      "them\n",
      "<br/>\n",
      "themselves\n",
      "<br/>\n",
      "then\n",
      "<br/>\n",
      "there\n",
      "<br/>\n",
      "there's\n",
      "<br/>\n",
      "these\n",
      "<br/>\n",
      "they\n",
      "<br/>\n",
      "they'd\n",
      "<br/>\n",
      "they'll\n",
      "<br/>\n",
      "they're\n",
      "<br/>\n",
      "they've\n",
      "<br/>\n",
      "this\n",
      "<br/>\n",
      "those\n",
      "<br/>\n",
      "through\n",
      "<br/>\n",
      "to\n",
      "<br/>\n",
      "too\n",
      "<br/>\n",
      "under\n",
      "<br/>\n",
      "until\n",
      "<br/>\n",
      "up\n",
      "<br/>\n",
      "very\n",
      "<br/>\n",
      "was\n",
      "<br/>\n",
      "wasn't\n",
      "<br/>\n",
      "we\n",
      "<br/>\n",
      "we'd\n",
      "<br/>\n",
      "we'll\n",
      "<br/>\n",
      "we're\n",
      "<br/>\n",
      "we've\n",
      "<br/>\n",
      "were\n",
      "<br/>\n",
      "weren't\n",
      "<br/>\n",
      "what\n",
      "<br/>\n",
      "what's\n",
      "<br/>\n",
      "when\n",
      "<br/>\n",
      "when's\n",
      "<br/>\n",
      "where\n",
      "<br/>\n",
      "where's\n",
      "<br/>\n",
      "which\n",
      "<br/>\n",
      "while\n",
      "<br/>\n",
      "who\n",
      "<br/>\n",
      "who's\n",
      "<br/>\n",
      "whom\n",
      "<br/>\n",
      "why\n",
      "<br/>\n",
      "why's\n",
      "<br/>\n",
      "with\n",
      "<br/>\n",
      "won't\n",
      "<br/>\n",
      "would\n",
      "<br/>\n",
      "wouldn't\n",
      "<br/>\n",
      "you\n",
      "<br/>\n",
      "you'd\n",
      "<br/>\n",
      "you'll\n",
      "<br/>\n",
      "you're\n",
      "<br/>\n",
      "you've\n",
      "<br/>\n",
      "your\n",
      "<br/>\n",
      "yours\n",
      "<br/>\n",
      "yourself\n",
      "<br/>\n",
      "yourselves\n"
     ]
    }
   ],
   "source": [
    "stopwords_en = []\n",
    "\n",
    "for col in cols:\n",
    "    for w in col.childGenerator():\n",
    "        print(w)\n",
    "        if w.__class__ == NavigableString:\n",
    "            stopwords_en.append(w)\n",
    "\n",
    "with open('./work/stopwords_en.txt', 'w') as f:\n",
    "    for word in stopwords_en:\n",
    "        f.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 work/stopwords_en.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l work/stopwords_en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/testfunc_is_stop_word.py\n"
     ]
    }
   ],
   "source": [
    "%%file ./src/testfunc_is_stop_word.py\n",
    "#!/usr/bin/env python3\n",
    "import unittest\n",
    "\n",
    "class Test(unittest.TestCase):\n",
    "    def testfunc_is_stopword(self):\n",
    "        self.assertTrue(is_stopword('in'))\n",
    "        self.assertFalse(is_stopword('play'))\n",
    "\n",
    "\n",
    "with open('./work/stopwords_en.txt') as f:\n",
    "    stopwords_en = [word.rstrip() for word in f]   \n",
    "\n",
    "def is_stopword(word):\n",
    "    return True if word in stopwords_en else False\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x ./src/testfunc_is_stop_word.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!./src/testfunc_is_stop_word.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='prob72'>\n",
    "# 72. 素性抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "極性分析に有用そうな素性を各自で設計し，学習データから素性を抽出せよ．<br>\n",
    "素性としては，レビューからストップワードを除去し，各単語をステミング処理したものが最低限のベースラインとなるであろう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>ベースライン</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counter -> DictVectorizerよりCountVectorizer使う方が早いらしい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import stem\n",
    "\n",
    "def make_dataset(fname):\n",
    "    \n",
    "    stemmer = stem.PorterStemmer()\n",
    "    with open('./work/stopwords_en.txt') as f:\n",
    "        stopwords_en = [word.rstrip() for word in f]\n",
    "    \n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            pol, text = line.split(maxsplit=1)\n",
    "            # 1文中のstopwordではない語をstemmingして連結\n",
    "            seq = ' '.join(stemmer.stem(w) for w in text.rstrip().split() if w not in stopwords_en)\n",
    "            \n",
    "            yield seq, pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10662, 13376)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "['00', '000', '007', '10', '100', '101', '102', '103', '104', '105']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "CV = CountVectorizer()\n",
    "X = CV.fit_transform(seq for seq, pol in make_dataset('./work/sentiment.txt'))\n",
    "ylabel = np.array([pol for seq, pol in make_dataset('./work/sentiment.txt')]).astype(np.int32)\n",
    "features = CV.get_feature_names()\n",
    "\n",
    "print(X.shape)\n",
    "print(X.toarray())\n",
    "print(features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1  1 ...  1 -1 -1]\n",
      "10662\n"
     ]
    }
   ],
   "source": [
    "print(ylabel)\n",
    "print(len(ylabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "素性の数が13376..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**if ... in ... 等よりもfilterを使うとスマートに書ける**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 素性の数を削りつつも同等のパフォーマンスが出せないか??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1. 分類のキーになりそうな品詞のみ使う -> 後の問題で重みが高かったもの(形容詞, 副詞) + 間投詞, punct</h4>\n",
    "これはあんまりよくなかった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_analyzer(string):\n",
    "    \n",
    "    tagset = ('JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS', 'UH', '.')\n",
    "    stemmer = stem.PorterStemmer()\n",
    "    return [stemmer.stem(word) for word, pos in pos_tag(word_tokenize(string)) if pos in tagset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10662, 6922)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "['!', \"'60s-homag\", \"'a\", \"'altern\", \"'artist\", \"'best\", \"'black\", \"'blue\", \"'charli\", \"'cherish\"]\n"
     ]
    }
   ],
   "source": [
    "CV_tag = CountVectorizer(analyzer=tag_analyzer)\n",
    "X_tag = CV_tag.fit_transform(seq for seq, pol in make_dataset('./work/sentiment.txt'))\n",
    "ylabel = np.array([pol for seq, pol in make_dataset('./work/sentiment.txt')]).astype(np.int32)\n",
    "features = CV_tag.get_feature_names()\n",
    "\n",
    "print(X_tag.shape)\n",
    "print(X_tag.toarray())\n",
    "print(features[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2. TfidfVectorizerで語の重要度に基づいた素性を作る + bi-gram featureの導入, feature数をかなり制限</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10662, 3000)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "['10', '10 minut', '100', '11', '12', '13', '15', '19', '20', '2002']\n"
     ]
    }
   ],
   "source": [
    "TfV = TfidfVectorizer(ngram_range=(1,2), max_features=3000)\n",
    "X_rev = TfV.fit_transform(seq for seq, pol in make_dataset('./work/sentiment.txt'))\n",
    "ylabel = np.array([pol for seq, pol in make_dataset('./work/sentiment.txt')]).astype(np.int32)\n",
    "features = TfV.get_feature_names()\n",
    "\n",
    "print(X_rev.shape)\n",
    "print(X_rev.toarray())\n",
    "print(features[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='prob73'>\n",
    "# 73. 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "72で抽出した素性を用いて，ロジスティック回帰モデルを学習せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習用とテスト用にデータを分割\n",
    "- sklearn.model_selection.train_test_split</br>\n",
    "引数random_stateに乱数シードを与える(再現性の問題)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>ベースライン</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabel, test_size=0.1, random_state=0)\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0] == y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1] == X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.のやつ</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C$=$\\frac{1}{\\lambda}$ -> 正規化係数lambdaが大きいとデータの少しの揺らぎには影響されにくくなる -> 汎化性能が上がる / lambdaが小さいと重みが大きくなりがち -> よりtraining dataにはfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rev, X_test_rev, y_train, y_test = train_test_split(X_rev, ylabel, test_size=0.1, random_state=0)\n",
    "lr_rev = LogisticRegression(random_state=0, C=0.9)\n",
    "lr_rev.fit(X_train_rev.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='prob74'>\n",
    "# 74. 予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "73で学習したロジスティック回帰モデルを用い，与えられた文の極性ラベル（正例なら\"+1\"，負例なら\"-1\"）と，その予測確率を計算するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>ベースライン</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_label(sentence, cv:CountVectorizer, lr:LogisticRegression):\n",
    "    X = cv.transform(sentence)\n",
    "    label = lr.predict(X)[0]\n",
    "    prob = np.max(lr.predict_proba(X), axis=1)[0]\n",
    "    return '予測ラベル:{}, 予測確率:{}'.format(label, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "予測ラベル:-1, 予測確率:0.6052118347281297\n",
      "予測ラベル:1, 予測確率:0.8640079475525666\n"
     ]
    }
   ],
   "source": [
    "test_neg = ['simplistic , silly and tedious .']\n",
    "test_pos = ['the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .']\n",
    "print(pred_label(test_neg, CV, lr))\n",
    "print(pred_label(test_pos, CV, lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='prob75'>\n",
    "# 75. 素性の重み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "73で学習したロジスティック回帰モデルの中で，重みの高い素性トップ10と，重みの低い素性トップ10を確認せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>ベースライン</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_w_rank = np.argsort(lr.coef_[0])[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重み1位のindexと重み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:3868, weight:2.091319473927551\n"
     ]
    }
   ],
   "source": [
    "print('idx:{}, weight:{}'.format(idx_w_rank[0], lr.coef_[0][idx_w_rank[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↓ 教師データの型指定をしなかった場合にはネガティブな語の重みが正になるように学習された...ラベルがintじゃないときには教師データの先に出てきた方のラベルが正になるのかもしれない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top10:\n",
      "Top1 feature:engross, weight:2.091319473927551\n",
      "Top2 feature:refresh, weight:1.9473297048576608\n",
      "Top3 feature:unexpect, weight:1.7758357637175628\n",
      "Top4 feature:marvel, weight:1.7341953888166433\n",
      "Top5 feature:resist, weight:1.6936911225376976\n",
      "Top6 feature:smarter, weight:1.6535320870662475\n",
      "Top7 feature:comfort, weight:1.6386789074659236\n",
      "Top8 feature:warm, weight:1.6288718001319096\n",
      "Top9 feature:remark, weight:1.6270403739833512\n",
      "Top10 feature:solid, weight:1.586225009442439\n",
      "Worst10:\n",
      "Worst1 feature:bore, weight:-2.116005658243827\n",
      "Worst2 feature:dull, weight:-2.000369206245822\n",
      "Worst3 feature:fail, weight:-1.791940138812256\n",
      "Worst4 feature:neither, weight:-1.7862470997539772\n",
      "Worst5 feature:mediocr, weight:-1.7430952487758546\n",
      "Worst6 feature:junk, weight:-1.7022114402167012\n",
      "Worst7 feature:plod, weight:-1.6716314221261592\n",
      "Worst8 feature:badli, weight:-1.6168982108900956\n",
      "Worst9 feature:routin, weight:-1.6028766515782666\n",
      "Worst10 feature:bland, weight:-1.5980099647007793\n"
     ]
    }
   ],
   "source": [
    "idx_w_top10 = idx_w_rank[:10]\n",
    "idx_w_worst10 = idx_w_rank[::-1][:10]\n",
    "\n",
    "print('Top10:')\n",
    "for i, v in enumerate(idx_w_top10, start=1):\n",
    "    print('Top{} feature:{}, weight:{}'.format(i, features[v], lr.coef_[0][v]))\n",
    "\n",
    "print('Worst10:')\n",
    "for i, v in enumerate(idx_w_worst10, start=1):\n",
    "    print('Worst{} feature:{}, weight:{}'.format(i, features[v], lr.coef_[0][v]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='prob76'>\n",
    "# 76. ラベル付け"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**学習データに対して**ロジスティック回帰モデルを適用し，正解のラベル，予測されたラベル，予測確率をタブ区切り形式で出力せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>ベースライン</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train dataでの精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_result_table(X, y, lr:LogisticRegression):\n",
    "    label = lr.predict(X)\n",
    "    prob = np.max(lr.predict_proba(X), axis=1)\n",
    "\n",
    "    for cor, pred, pred_prob in zip(y, label, prob):\n",
    "        yield cor, pred, pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t1\t0.7308438602101379\n",
      "-1\t-1\t0.771345163747875\n",
      "-1\t-1\t0.7188460903595768\n",
      "1\t1\t0.7983573567984854\n",
      "-1\t-1\t0.6886476895011939\n",
      "-1\t-1\t0.9778462810482675\n",
      "-1\t-1\t0.9636143465948221\n",
      "-1\t-1\t0.8846569839067747\n",
      "1\t-1\t0.7692389050491047\n",
      "1\t1\t0.7621512395791971\n"
     ]
    }
   ],
   "source": [
    "for cor, pred, pred_prob in itertools.islice(get_result_table(X_train, y_train, lr), 10):\n",
    "    print('{}\\t{}\\t{}'.format(cor, pred, pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.のやつ</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t1\t0.6061920360725934\n",
      "-1\t-1\t0.6166340965255432\n",
      "-1\t1\t0.5567253668090474\n",
      "1\t1\t0.7172414492717472\n",
      "-1\t-1\t0.6496702172104625\n",
      "-1\t-1\t0.863998397204088\n",
      "-1\t-1\t0.8336191732977347\n",
      "-1\t-1\t0.7607975909779756\n",
      "1\t-1\t0.8286353231753999\n",
      "1\t1\t0.6383494657594139\n"
     ]
    }
   ],
   "source": [
    "label = lr_rev.predict(X_train_rev)\n",
    "prob = np.max(lr_rev.predict_proba(X_train_rev), axis=1)\n",
    "\n",
    "for cor, pred, pred_prob in itertools.islice(zip(y_train, label, prob), 10):\n",
    "    print(cor, pred, pred_prob, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>pandasで</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>正解</th>\n",
       "      <th>予測値</th>\n",
       "      <th>正誤</th>\n",
       "      <th>予測確率</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.730844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.771345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.718846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.798357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.688648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9590</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.723292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9591</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.968374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9592</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.652382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9593</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.787856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9594</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.761410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9595 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      正解  予測値    正誤      予測確率\n",
       "0      1    1  True  0.730844\n",
       "1     -1   -1  True  0.771345\n",
       "2     -1   -1  True  0.718846\n",
       "3      1    1  True  0.798357\n",
       "4     -1   -1  True  0.688648\n",
       "...   ..  ...   ...       ...\n",
       "9590   1    1  True  0.723292\n",
       "9591   1    1  True  0.968374\n",
       "9592  -1   -1  True  0.652382\n",
       "9593   1    1  True  0.787856\n",
       "9594  -1   -1  True  0.761410\n",
       "\n",
       "[9595 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = lr.predict(X_train)\n",
    "prob = np.max(lr.predict_proba(X_train), axis=1)\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "df = pd.DataFrame(y_train, columns=['正解'])\n",
    "df['予測値'] =  pd.Series(label)\n",
    "df['正誤'] = pd.Series(y_train == label)\n",
    "df['予測確率'] = pd.Series(prob)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9503908285565399\n"
     ]
    }
   ],
   "source": [
    "print(lr.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8400208441896821\n"
     ]
    }
   ],
   "source": [
    "print(lr_rev.score(X_train_rev, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>異常にoverfitしてる, というかbaseline強い</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test dataでの精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.753514526710403\n"
     ]
    }
   ],
   "source": [
    "print(lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "素性の数を3000まで減らしてもパフォーマンス向上 -> Tf-idfで重要な語にfocusできている?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7703842549203374\n"
     ]
    }
   ],
   "source": [
    "print(lr_rev.score(X_test_rev, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='prob77'>\n",
    "# 77. 正解率の計測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "76の出力を受け取り，予測の正解率，正例に関する適合率，再現率，F1スコアを求めるプログラムを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def calc_score(cor, pred):\n",
    "    acc = accuracy_score(cor, pred)\n",
    "    prec = precision_score(cor, pred)\n",
    "    rec = recall_score(cor, pred)\n",
    "    F1 = f1_score(cor, pred)\n",
    "    \n",
    "    return acc, prec, rec, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9503908285565399, precision:0.9542415378186377, recall:0.9467247097844113, F1:0.950468262226847\n"
     ]
    }
   ],
   "source": [
    "# 一回zipして各データに対する正解, 予測...にした後に正解の配列, 予測の配列...を作り直してて頭悪い\n",
    "cor = [cor for cor, *_ in get_result_table(X_train, y_train, lr)]\n",
    "pred = [pred for _, pred, _ in get_result_table(X_train, y_train, lr)]\n",
    "\n",
    "acc, prec, rec, F1 = calc_score(cor, pred)\n",
    "print('accuracy:{}, precision:{}, recall:{}, F1:{}'.format(acc, prec, rec, F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='prob78'>\n",
    "# 78. 5分割交差検定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "76-77の実験では，学習に用いた事例を評価にも用いたため，正当な評価とは言えない．<br>\n",
    "すなわち，分類器が訓練事例を丸暗記する際の性能を評価しており，モデルの汎化性能を測定していない．<br>\n",
    "そこで，5分割交差検定により，極性分類の正解率，適合率，再現率，F1スコアを求めよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>そもそも訓練事例をテストにも使うとかいうぶっ飛び設定だった</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $k$-分割交差検証<br>\n",
    "標本を$k$個に分割してそのうち1個をテスト事例, 残り$k-1$個を訓練事例として, $k$個の標本群それぞれをテスト事例にして$k$回の検証を行う手法<br>\n",
    "$k$回の結果の平均を推定値とする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラス分類では通常層化$k$-分割交差検証が行われる -> 元のデータと各クラスに属するインスタンスの割合が同じになるように分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_val_scoreはscoringにstringしか渡せないけどcross_validateはリストで渡せる -> そっち使おう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "lr_5cross = LogisticRegression(random_state=0)\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=0)\n",
    "acc_5cross = np.mean(cross_val_score(lr_5cross, X, ylabel, scoring='accuracy', cv=kfold))\n",
    "prec_5cross = np.mean(cross_val_score(lr_5cross, X, ylabel, scoring='precision', cv=kfold))\n",
    "rec_5cross = np.mean(cross_val_score(lr_5cross, X, ylabel, scoring='recall', cv=kfold))\n",
    "F1_5cross = np.mean(cross_val_score(lr_5cross, X, ylabel, scoring='f1', cv=kfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7492959517224038, precision:0.749908095451498, recall:0.7484495640140598, F1:0.7491027521766396\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:{}, precision:{}, recall:{}, F1:{}'.format(acc_5cross, prec_5cross, rec_5cross, F1_5cross))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='prob79'>\n",
    "# 79. 適合率-再現率グラフの描画"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロジスティック回帰モデルの分類の閾値を変化させることで，適合率-再現率グラフを描画せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precision-Recall curve<br>\n",
    "ラベルが+1に分類される分類確率のthresholdを変化させたときのprecision, recall値"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 閾値が非常に高いと -> 左上 -> 確かに正しいものを選べてはいるけど, 正解ラベル中のほとんどは見逃してしまう\n",
    "2. 閾値が低いと -> 右下 -> すべてを+1に分類するからすべての正例を選べるけど, precisionは正例数/訓練データ数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "prec, rec, threshold = precision_recall_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(prec[len(threshold)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0019723865877712033\n"
     ]
    }
   ],
   "source": [
    "print(rec[len(threshold)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4970588235294118\n"
     ]
    }
   ],
   "source": [
    "print(prec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(rec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'2-class Precision-Recall curve')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.step(rec, prec, color='b', alpha=0.2, where='mid')\n",
    "plt.fill_between(rec, prec, step='mid', alpha=0.2, color='b')\n",
    "\n",
    "for i in range(21):\n",
    "    # threshold=0.05刻みでのprec, recの値\n",
    "    close_point = np.argmin(np.abs(threshold - (i/20)))\n",
    "    plt.plot(rec[close_point], prec[close_point], 'o')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
